# **************************************************************************** #
#                                                                              #
#                                                         :::      ::::::::    #
#    _ThreadPool.docs                                   :+:      :+:    :+:    #
#                                                     +:+ +:+         +:+      #
#    By: mmaria-d <mmaria-d@student.42lisboa.com    +#+  +:+       +#+         #
#                                                 +#+#+#+#+#+   +#+            #
#    Created: 2025/01/06 23:44:33 by mmaria-d          #+#    #+#              #
#    Updated: 2025/01/07 00:20:00 by mmaria-d         ###   ########.fr        #
#                                                                              #
# **************************************************************************** #

So this ThreadPool is not very sophisticated and there are clear areas for improvement.

In any case:

We can use it to execute tasks in parallel.

The main class is ThreadPool<ThreadBacklog, TaskBacklog>
                        -> at most, it can run ThreadBacklog threads
                            -> if exceeded asserts
                        -> at most, it can queue up TaskBacklog tasks
                            -> if exceeded, we give option to the user to wait for a slot, more on that later


Single Constructor and no Copy/Assignment:

ThreadPool(initial number of threads). It will spawn that amount of threads, from which you can add or subtract
at runtime.

Now, to add a task, we call

    bool				ThreadPool::addTask(IThreadTask* newTask, bool waitForSlot = false);

It takes an interface pointer to a Task.
The interface attempts to be very basic, to allow total flexibility to the user to come up with anything that might be required

class IThreadTask
{
	public:
		virtual 				~IThreadTask() {};
		virtual void			execute() = 0;
};

So, to add a task to the Pool, you need to create an implementation of this IThreadTask interface, 
and implement a public execute() method that will be called when it comes its turn to be executed.
For instance, from the test cases:

class FiboTask : public IThreadTask
{
	public:
		FiboTask() : m_sequencePosition(0), m_placeResult(NULL) {}
		FiboTask(unsigned int n, long* placeResult) : m_sequencePosition(n), m_placeResult(placeResult) {}
		void execute()
		{
			*m_placeResult = fibGood(m_sequencePosition);
		}
	private:
		unsigned int 	m_sequencePosition;
		long* 			m_placeResult;
};

So i create a FiboTask, that has all parameters required, an input for instance, somewhere to place the result, etc.
And when we call execute() it calls a fibonacci algorithm and places the result in m_placeResult to later access.

We then do ThreadPool::addTask, passing Fibotask (or any implementation that complies with the IThreadTask interface) to it.

The second parameter to addTask, serves to allow the user to wait for a spot in the TaskQueue (because we have a max backlog)
and the program will block until there is a slot available, and then proceed.

Addtask returns true for successfully adding a task to the ThreadPool -> it will fail if waitForSlot = false and the 
queue is full, just so the user can check if it was successfull or not.

/*****************************/

After passing a series of tasks, we may want to access results. The main way is to call

ThreadPool::waitForCompletion()
    -> it simply waits until all the tasks in the queue are executed and the queue is empty
    -> after that, if you passed locations to place results to your tasks, you can check values, etcetc (examples in _Tests)


/********************************/

It is a bit complicated to make the program stop and wait if you want to have the return of a single Task.
On test3.cpp i attempted at implementing very concrete Promises and Futures examples:

    You create a Promise (implementing IThreadTask), which yields a future and they share "State".
    So, Future.get() will block the program until Promise is executed and signals completion.

    After that, Future will access the result that is stored in the shared State between the two.
    (state must have condition variables and mutexes and all that good stuff to be able to communicate with Future, interthreads)

    It is not robust at all, just for demonstration purposes.
    State should be a shared pointer, such that it outlives both the promise and the future.
    Anyways, just a rough example

/*****************************/

You can explicitely call ThreadPool::destroy() to destroy all threads, and eventually even adding threads and tasks again.

::destroy() takes boolean parameter, waitForCompletion -> allows the user to decide whether to wait for completion of all tasks
or destroy everything right away.

The worse, more forcefull wait to do it is to call ThreadPool::forceDestroy(), which send SIGKILL to all threads lol memoryleaks 
everywhere, last resort stuff......

/*********************************/

Currently, this threadPool implementation works as Fire-And-Forget:
    You don't get to cancel your tasks after submiting

The ThreadPool also does not copy any ThreadTasks (i did have a clone() method on the interface before),
which has the positive of saving memory, and some negatives.....
    -> what if the user attempts to change the concrete ThreadTask after submiting to the pool? -> race condition
    -> what if for some reason, concrete ThreadTask goes out of scope and the pool attempts to execute it? -> SEGFAULT
    -> actually, even with clone(), if the ThreadTask is referencing some memory location and the user at main thread attempts to
        write to it, you also get a race condition.

Also, the pool is not really ready for having threads adding tasks themselves indefinitely.
    Consider this, the ThreadPool has 5 threads, and you submit a task that has 6 levels of recursion, calling addTask
    at each level, waitForSlot = true .... -> deadlock

    You can but have to be very mindful of how deep the tasks can be.

    These are things certainly beyond the scope of the project, as most of Toolkit lol

As you see, although it is fun, ThreadPools can be complicated.

/**********************************/

Good news, if you send 10 ServerWorker.run() to a ThreadPool with 10 threads, it works, which is the main purpose of this BS.

/**********************************/

Example:


const int numberOfTasks = 100;

// threadPool with up to 100 workers, 1000 task backlog, and starts with 20 running threads
ThreadPool<100, 1000> tp(20);
std::vector<long> 			fiboExpected;           //just a vector of expected results
std::vector<long>			fiboPlaceResult;        // just a vector for the FiboTask to place results
std::vector<FiboTask> 		tasks;                  // a vector of tasks themselves

fiboExpected.reserve(numberOfTasks);                // reserve, always good policy if you know the size
fiboPlaceResult.reserve(numberOfTasks);
tasks.reserve(numberOfTasks);

for (size_t i = 0; i < numberOfTasks; ++i)
{
    fiboExpected.push_back(fibGood(i));                     // prepare the expected value
    tasks.push_back(FiboTask(i, &fiboPlaceResult[i]));      // create a new FiboTask, pass it the fibo sequence number and where to put the result
    tp.addTask(tasks[i]);                                   // add task, don't wait for slot if there are none available (100 tasks vs 1000 slots, no problem)
}
    
tp.waitForCompletion();                                    // wait until all the tasks have been executed and the queue is empty

for (size_t i = 0; i < fiboExpected.size(); ++i)            // compare the actual result vs what you expected, to see there is a match
{
    if (fiboExpected[i] != fiboPlaceResult[i])
        throw std::runtime_error("Didn't calculate fibonacci right");
}


/*****************************************/

Finally, here is the ThreadTask implementation we could use to run our parallel servers:

class ServerThreadTask : public IThreadTask
{
	public:
		ServerThreadTask(ServerWorker& worker) : m_worker(worker) {}
		ServerThreadTask(const ServerThreadTask& copy) : m_worker(copy.m_worker) {}
		~ServerThreadTask() {}

		void execute() { m_worker.run(); }
		
	private:
		ServerWorker& m_worker;

		ServerThreadTask& operator=(const ServerThreadTask& assign) { (void)assign; return (*this); }
};

/*********************************************/